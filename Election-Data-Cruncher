#!/usr/bin/env python3
from FEC_grabber import stream_file, copy_headers
import db_docker
from neo4j_db_api import Neo4jAPIException
import requests
import os
from zipfile import ZipFile
import csv
import numpy as np
import argparse
import subprocess

# dir to store files
dir = "./FEC_Election_Data"


def parse_args():
    '''
    Detect -c or --clean to remove the temp data dir and stop container
    Detect -q or --quick to limit the size of data import for quicker run time
    :return: args object
    '''
    parser = argparse.ArgumentParser()
    parser.add_argument("-c", "--clean", help="Remove temportary "
                                              "files and container.",
                        action="store_true")
    parser.add_argument("-q", "--quick",
                        help="Limit record imports for a faster bringup time "
                             "but fewer imported data records.",
                        action="store_true")
    args = parser.parse_args()

    # clean if -c arg included
    if args.clean:
        # remove data folder
        subprocess.call(['sh', './cleanup.sh'])
        print("Finished cleaning, exiting...")
        exit()
    return args


def main():
    # parse input args and store quick arg for data import count restrictions
    args = parse_args()
    quick = args.quick

    # files to download
    download_files = \
        ['https://www.fec.gov/files/bulk-downloads/2022/weball22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/cn22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/ccl22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/webl22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/cm22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/webk22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/indiv22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/pas222.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/oth22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/oppexp22.zip']
    # naming convention to split names on, so header can match data file
    # e.g. cm22 corresponds to cm_header_file
    split_number = "22"
    header_url = 'https://www.fec.gov/files/bulk-downloads/data_dictionaries/'
    header_files = ['cn_header_file.csv',
                    'ccl_header_file.csv',
                    'cm_header_file.csv',
                    'indiv_header_file.csv',
                    'pas2_header_file.csv',
                    'oth_header_file.csv',
                    'oppexp_header_file.csv']

    # download the FEC data files to local dir: ./FEC_Election_Data
    for file in download_files:
        # download the file if it doesnt exist
        zipped_file = stream_file(dir, file)
        if zipped_file is not None:
            with ZipFile(zipped_file, 'r') as zipObj:
                # extract zipped file to same dir
                zipObj.extractall(path=dir)

    # copy custom headers to new dir
    copy_headers('./FEC_header_repo', dir)

    # download header files
    for file in header_files:
        stream_file(dir, header_url + file)

    # convert data
    main_data = files_to_data(download_files, split_number, dir)

    # start docker instance
    neo4j_docker_db = db_docker.Neo4jDockerDB()

    # create a node to store which files have been imported
    id = None
    try:
        id = neo4j_docker_db.get_node_id_by_prop(" ", "Imported")
    except db_docker.Neo4jAPIException:
        id = neo4j_docker_db.create_node("Imported", " ")

    # import to nodes
    fec_data_to_neo4j(main_data, neo4j_docker_db, id, quick)


def files_to_data(download_files, split_number, dir):
    main_data = {}
    for file in download_files:
        base = os.path.basename(file).rsplit(split_number)[0]
        # handle individual contributions
        if base == 'indiv':
            continue
        basedir = dir + "/" + base
        # check if header file exists using established naming convention
        hfile = basedir + "_header_file.csv"
        dfile = basedir + ".txt"
        print(f"Opening FEC file ({dfile}) and storing data..")

        if os.path.exists(os.path.abspath(hfile)):
            fields = None
            data = []
            with open(hfile, 'r') as csvfile:
                # creating a csv reader object
                csvreader = csv.reader(csvfile)
                fields = next(csvreader)
            # corner case for non-standard FEC naming convention
            if not os.path.exists(dfile):
                dfile = basedir + f"{split_number}.txt"
            if not os.path.exists(dfile):
                dfile = dir + "/it" + f"{base}.txt"
            with open(dfile, 'r') as datafile:
                lines = datafile.readlines()
                for line in lines:
                    # badly formatted file correction, remove last |
                    if base == "oppexp":
                        line = line.rstrip()[:-1]
                    data_count = len(line.rstrip().split("|"))
                    flen = len(fields)
                    # if the number of fields doesn't match the number of data
                    # records, raise an exception
                    if len(fields) != data_count:
                        raise Exception(f"Data import lenth mismatch "
                                        f"({data_count} vs {flen}) between:\n"
                                        f"{line}\nand\n{fields}")
                    data.append(line.rstrip().split("|"))
            main_data.update(fec_data_to_dict(data, fields, base))
        else:
            raise Exception(f"Header file not found: {hfile}")
    return main_data


def fec_data_to_dict(data, header, base):
    '''
    Organize data into dict to determine which kind of nodes to create
    :param data: array of data corresponding to a single line
    :param header: array of keys to identify data
    :param base: name to determine which kind of data is being imported
    :return: dict of dicts with organized metadata
    '''
    out = {}
    pointer = None
    # all candidates file - summary financial information for each candidate
    if base == "weball":
        out['all candidates'] = []
        pointer = out['all candidates']
    # candidate master file - summary financial information for each candidate
    elif base == "cn":
        out['candidate master'] = []
        pointer = out['candidate master']
    # link between candidate info to info about their committee
    elif base == "ccl":
        out['candidate committee linkage'] = []
        pointer = out['candidate committee linkage']
    # summary financial information for each campaign committee
    elif base == "webl":
        out['current campaigns'] = []
        pointer = out['current campaigns']
    # one record for each committee registered with the FEC
    elif base == "cm":
        out['committee master'] = []
        pointer = out['committee master']
    # overall receipts and disbursements for each PAC and party committee
    elif base == "webk":
        out['pac summary'] = []
        pointer = out['pac summary']
    # expenditure made by a PAC, party committee, candidate committee,
    # or other federal committee
    elif base == "pas2":
        out['contributions'] = []
        pointer = out['contributions']
    # transactions between committees
    elif base == "oth":
        out['intercommittee transactions'] = []
        pointer = out['intercommittee transactions']
    # reported FEC disbursements
    elif base == "oppexp":
        out['operating expenditures'] = []
        pointer = out['operating expenditures']
    else:
        raise Exception(f"Unable to determine FEC file type: {base}")

    # process array of lines into dicts that will be later converted to nodes
    for line in data:
        node = {}
        for count, key in enumerate(header):
            if str(line[count]).isdigit():
                val = np.int64(line[count])
            else:
                try:
                    val = float(line[count])
                    # skip huge numbers
                    if val == float('inf'):
                        val = 0
                except ValueError:
                    # remove characters that will cause issues later
                    val = line[count].replace("\"", '').replace("\'", '')
                    val = f'"{val}"'
            node[key] = val
        pointer.append(node)
    return out


def fec_data_to_neo4j(main_data, neo4jobj, imported_id, quick):
    '''
    This takes the main_data dict, parses it, and uploads it to the neo4j
    database
    :param main_data: data dict with FEC data populated with specific keys
    :param neo4jobj: neo4j object that executes commands
    :param imported_id: id of imported node to record what has been added
    :return:
    '''
    print("Importing data to neo4j...")
    total = 0
    # weball file
    if not get_imported(imported_id, neo4jobj, "weball"):
        # weball
        for count, cand in enumerate(main_data['all candidates']):
            # format dict string to neo4j property input
            props = format_props(cand)
            neo4jobj.create_node("Candidate", props)
            total = count
        print(f"Created {total} candidate nodes.")
        # record on the Imported node so we have a record this was processed
        neo4jobj.set_property_by_id(imported_id, "weball", True)
    else:
        print("Skipping weball, already imported.")

    # cm file
    if not get_imported(imported_id, neo4jobj, "cm"):
        for count, cand in enumerate(main_data['committee master']):
            # format dict string to neo4j property input
            props = format_props(cand)
            neo4jobj.create_node("Committee", props)
            total = count
        print(f"Created {total} committee nodes.")
        # record on the Imported node so we have a record this was processed
        neo4jobj.set_property_by_id(imported_id, "cm", True)
    else:
        print("Skipping cm, already imported.")

    # webl - AKA current committees
    if not get_imported(imported_id, neo4jobj, "webl"):
        for count, cand in enumerate(main_data['current campaigns']):
            # format dict string to neo4j property input
            props = str(cand).replace('{', '').replace('}', '').replace("\'",
                                                                        '')
            props = props.replace('\\', '')
            neo4jobj.create_node("Committee", props)
            total = count
        print(f"Created {total} committee nodes.")
        # record on the Imported node so we have a record this was processed
        neo4jobj.set_property_by_id(imported_id, "webl", True)
    else:
        print("Skipping webl, already imported.")

    # cn - candidate file
    if not get_imported(imported_id, neo4jobj, "cn"):
        for count, cand in enumerate(main_data['candidate master']):
            # format dict string to neo4j property input
            props = format_props(cand)
            cid = neo4jobj.create_node("Candidate", props)
            party_id = None
            # create party node
            try:
                party_id = neo4jobj.get_node_id_by_prop(
                    f"Name:{cand['CAND_PTY_AFFILIATION']}",
                    'Party')
            except (Neo4jAPIException, TypeError):
                party_id = neo4jobj.create_node("Party",
                                                f"Name:{cand['CAND_PTY_AFFILIATION']}")
                neo4jobj.create_relationship_by_id(party_id, cid, "PARTY_OF")
            total = count
        print(f"Created {total} candidate nodes.")
        # record on the Imported node so we have a record this was processed
        neo4jobj.set_property_by_id(imported_id, "cn", True)
    else:
        print("Skipping cn, already imported.")

    # ccl - links file
    if not get_imported(imported_id, neo4jobj, "ccl"):
        for count, cand in enumerate(main_data['candidate committee linkage']):
            # apparently FEC files can be missing current year candidates?
            # so let's wrap things in a try/catch and just print failures
            try:
                candid = neo4jobj.get_node_id_by_prop(
                    f"CAND_ID:{cand['CAND_ID']}",
                    'Candidate')
            except (Neo4jAPIException, TypeError):
                # data is missing candidate or is not current, skip it.
                continue
            try:
                # get the committee this candidate is linked to
                cid = cand.get('CAND_ID')
                cmte = neo4jobj.get_node_id_by_prop(f"CAND_ID:{cid}",
                                                    'Committee')
            except (Neo4jAPIException, TypeError):
                # couldn't find it, try getting the candidate node committee
                # id data instead
                cid = cand.get('CMTE_ID')
                try:
                    cmte = neo4jobj.get_node_id_by_prop(f"CMTE_ID:{cid}",
                                                        'Committee')
                except (Neo4jAPIException, TypeError):
                    # can't find candidate or committee match because of data
                    # integrity issues. Skip it then.
                    continue
            neo4jobj.create_relationship_by_id(cmte, candid, "COMMITTEE_OF")
            total = count
        print(f"Created {total} committee/candidate links.")
        # record on the Imported node so we have a record this was processed
        neo4jobj.set_property_by_id(imported_id, "ccl", True)
    else:
        print("Skipping ccl, already imported.")

    # webk - pac summary file
    if not get_imported(imported_id, neo4jobj, "webk"):
        for count, cand in enumerate(main_data['pac summary']):
            # format dict string to neo4j property input
            props = format_props(cand)
            neo4jobj.create_node("PAC", props)
            total = count
        print(f"Created {total} PAC nodes.")
        # record on the Imported node so we have a record this was processed
        neo4jobj.set_property_by_id(imported_id, "webk", True)
    else:
        print("Skipping webk, already imported.")

    # pas2 - contributions file
    if not get_imported(imported_id, neo4jobj, "pas2"):
        for count, cand in enumerate(main_data['contributions']):
            # format dict string to neo4j property input
            props = format_props(cand)
            cont = neo4jobj.create_node("Contribution", props)
            cid = cand.get('CMTE_ID')
            try:
                cmte = neo4jobj.get_node_id_by_prop(f"CMTE_ID:{cid}",
                                                    'Committee')
            except (Neo4jAPIException, TypeError):
                # can't find candidate or committee match because of data
                # integrity issues. Skip it then.
                continue
            neo4jobj.create_relationship_by_id(cmte, cont, "CONTRIBUTION_TO")
            total = count
            if quick and count > 10000:
                break
        print(f"Created {total} PAC contribution nodes.")
        # record on the Imported node so we have a record this was processed
        neo4jobj.set_property_by_id(imported_id, "pas2", True)
    else:
        print("Skipping pas2, already imported.")

    # oth - transactions file
    if not get_imported(imported_id, neo4jobj, "oth"):
        for count, t in enumerate(main_data['intercommittee transactions']):
            # format dict string to neo4j property input
            props = format_props(t)
            tid = neo4jobj.create_node("Transaction", props)
            cid = t.get('CMTE_ID')
            try:
                cmte = neo4jobj.get_node_id_by_prop(f"CMTE_ID:{cid}",
                                                    'Committee')
            except (Neo4jAPIException, TypeError):
                # can't find candidate or committee match because of data
                # integrity issues. Skip it then.
                continue
            neo4jobj.create_relationship_by_id(cmte, tid, "CONTRIBUTION_TO")
            total = count
            if quick and count > 10000:
                break
        print(f"Created {total} transaction nodes.")
        # record on the Imported node so we have a record this was processed
        neo4jobj.set_property_by_id(imported_id, "oth", True)
    else:
        print("Skipping oth, already imported.")

    # opp - expenditures file
    if not get_imported(imported_id, neo4jobj, "opp"):
        for count, t in enumerate(main_data['operating expenditures']):
            # format dict string to neo4j property input
            props = format_props(t)
            exp = neo4jobj.create_node("Expense", props)
            # get the committee id
            cid = t.get('CMTE_ID')
            try:
                # fetch the neo4j id for the committee node
                cmte = neo4jobj.get_node_id_by_prop(f"CMTE_ID:{cid}",
                                                    'Committee')
            except (Neo4jAPIException, TypeError):
                # can't find candidate or committee match because of data
                # integrity issues. Skip it then.
                continue
            # create link between committee and the expense
            neo4jobj.create_relationship_by_id(exp, cmte, "EXPENSE_OF")
            total = count
            # stop at 10000 if quick arg detected
            if quick and count > 10000:
                break
        print(f"Created {total} expense nodes.")
        # record on the Imported node so we have a record this was processed
        neo4jobj.set_property_by_id(imported_id, "opp", True)
    else:
        print("Skipping opp, already imported.")
    print("Finished Importing Data.")


def format_props(s):
    '''
    format the property string by removing characters that cause problems
    with Cypher syntax
    :param s: input string to sanitize
    :return: formatted/sanitized string
    '''
    props = str(s).replace('{', '').replace('}', '').replace("\'", '')
    props = props.replace('\\', '')
    return props


def get_imported(imported_id, neo4jobj, name):
    '''
    fetch the data for the imported node
    :param imported_id: neo4j id of node with 'Imported' label
    :param neo4jobj: neo4j query object
    :param neo4jobj: matching dataset to check
    :return: True if imported, false if not (raises keyerror and is caught)
    '''
    data = neo4jobj.get_node_properties_by_id(imported_id)
    try:
        return data[name]
    except KeyError:
        return False


if __name__ == '__main__':
    main()
