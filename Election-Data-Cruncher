#!/usr/bin/env python3
from FEC_grabber import stream_file, copy_headers
import db_docker
import requests
import os
from zipfile import ZipFile
import csv


def main():
    # dir to store files
    dir = "./FEC_Election_Data"
    # files to download
    download_files = \
        ['https://www.fec.gov/files/bulk-downloads/2022/weball22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/cn22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/ccl22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/webl22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/cm22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/webk22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/indiv22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/pas222.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/oth22.zip',
         'https://www.fec.gov/files/bulk-downloads/2022/oppexp22.zip']
    # naming convention to split names on, so header can match data file
    # e.g. cm22 corresponds to cm_header_file
    split_number = "22"
    header_url = 'https://www.fec.gov/files/bulk-downloads/data_dictionaries/'
    header_files = ['cn_header_file.csv',
                    'ccl_header_file.csv',
                    'cm_header_file.csv',
                    'indiv_header_file.csv',
                    'pas2_header_file.csv',
                    'oth_header_file.csv',
                    'oppexp_header_file.csv']

    # download the FEC data files to local dir: ./FEC_Election_Data
    for file in download_files:
        # download the file if it doesnt exist
        zipped_file = stream_file(dir, file)
        if zipped_file is not None:
            with ZipFile(zipped_file, 'r') as zipObj:
                # extract zipped file to same dir
                zipObj.extractall(path=dir)

    # copy custom headers to new dir
    copy_headers('./FEC_header_repo', dir)

    # download header files
    for file in header_files:
        stream_file(dir, header_url + file)

    # convert data
    main_data = files_to_data(download_files, split_number, dir)

    # start docker instance
    neo4j_docker_db = db_docker.Neo4jDockerDB()

    # create a node to store which files have been imported
    id = None
    try:
        id = neo4j_docker_db.get_node_id_by_prop(" ", "Imported")
    except db_docker.Neo4jAPIException:
        id = neo4j_docker_db.create_node("Imported", " ")

    # import to nodes
    fec_data_to_neo4j(main_data, neo4j_docker_db, id)


def files_to_data(download_files, split_number, dir):
    main_data = {}
    for file in download_files:
        base = os.path.basename(file).rsplit(split_number)[0]
        # handle individual contributions
        if base == 'indiv':
            continue
        basedir = dir + "/" + base
        # check if header file exists using established naming convention
        hfile = basedir + "_header_file.csv"
        dfile = basedir + ".txt"
        print(f"Opening FEC file ({dfile}) and storing data..")

        if os.path.exists(os.path.abspath(hfile)):
            fields = None
            data = []
            with open(hfile, 'r') as csvfile:
                # creating a csv reader object
                csvreader = csv.reader(csvfile)
                fields = next(csvreader)
            # corner case for non-standard FEC naming convention
            if not os.path.exists(dfile):
                dfile = basedir + f"{split_number}.txt"
            if not os.path.exists(dfile):
                dfile = dir + "/it" + f"{base}.txt"
            with open(dfile, 'r') as datafile:
                lines = datafile.readlines()
                for line in lines:
                    # badly formatted file correction, remove last |
                    if base == "oppexp":
                        line = line.rstrip()[:-1]
                    data_count = len(line.rstrip().split("|"))
                    flen = len(fields)
                    # if the number of fields doesn't match the number of data
                    # records, raise an exception
                    if len(fields) != data_count:
                        raise Exception(f"Data import lenth mismatch "
                                        f"({data_count} vs {flen}) between:\n"
                                        f"{line}\nand\n{fields}")
                    data.append(line.rstrip().split("|"))
            main_data.update(fec_data_to_dict(data, fields, base))
        else:
            raise Exception(f"Header file not found: {hfile}")
    return main_data


def fec_data_to_dict(data, header, base):
    '''
    Organize data into dict to determine which kind of nodes to create
    :param data: array of data corresponding to a single line
    :param base: name to determine which kind of data is being imported
    :return: dict of dicts with organized metadata
    '''
    out = {}
    pointer = None
    # all candidates file - summary financial information for each candidate
    if base == "weball":
        out['all candidates'] = []
        pointer = out['all candidates']
    # candidate master file - summary financial information for each candidate
    elif base == "cn":
        out['candidate master'] = []
        pointer = out['candidate master']
    # link between candidate info to info about their committee
    elif base == "ccl":
        out['candidate committee linkage'] = []
        pointer = out['candidate committee linkage']
    # summary financial information for each campaign committee
    elif base == "webl":
        out['current campaigns'] = []
        pointer = out['current campaigns']
    # one record for each committee registered with the FEC
    elif base == "cm":
        out['committee master'] = []
        pointer = out['committee master']
    # overall receipts and disbursements for each PAC and party committee
    elif base == "webk":
        out['pac summary'] = []
        pointer = out['pac summary']
    # expenditure made by a PAC, party committee, candidate committee,
    # or other federal committee
    elif base == "pas2":
        out['contributions'] = []
        pointer = out['contributions']
    # transactions between committees
    elif base == "oth":
        out['intercommittee transactions'] = []
        pointer = out['intercommittee transactions']
    # reported FEC disbursements
    elif base == "oppexp":
        out['operating expenditures'] = []
        pointer = out['operating expenditures']
    else:
        raise Exception(f"Unable to determine FEC file type: {base}")

    # process array of lines into dicts that will be later converted to nodes
    for line in data:
        node = {}
        for count, key in enumerate(header):
            val = line[count]
            try:
                val = float(val)
            except ValueError:
                try:
                    val = int(val)
                except ValueError:
                    # remove characters that will cause issues later
                    val = val.replace("\"", '').replace("\'", '')
                    val = f'"{val}"'
            node[key] = val
        pointer.append(node)
    return out


def fec_data_to_neo4j(main_data, neo4jobj, imported_id):
    total = 0
    for count, cand in enumerate(main_data['all candidates']):
        # format dict string to neo4j property input
        props = str(cand).replace('{', '').replace('}', '').replace("\'", '')
        props = props.replace('\\', '')
        neo4jobj.create_node("Candidate", props)
        total = count
    print(f"Created {total} candidate nodes.")
    for count, cand in enumerate(main_data['candidate master']):
        # format dict string to neo4j property input
        props = str(cand).replace('{', '').replace('}', '').replace("\'", '')
        props = props.replace('\\', '')
        neo4jobj.get_node_id_by_prop(f"CAND_ID:{cand['CAND_ID']}",
                                     'Candidate')
        neo4jobj.create_node_with_rel_to_id("Candidate", props)
        total = count



if __name__ == '__main__':
    main()
